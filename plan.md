# Multi-Source Knowledge Collector (Module 1): 
- newspaper3k
- Playwright
- DuckDuckGo API
- Wikipedia
- gnews

## YouTube & Multimedia Transcripts
- youtube-transcript-api
- langclain YoutubeLoader

# Ravana AGI Core - Development Roadmap

This document outlines the development plan and future directions for the Ravana AGI Core project. The goal is to continuously enhance the AGI's intelligence, autonomy, and capabilities.

## Phase 1: Solidify the Core Agentic Loop (Current Focus)

The immediate focus is on ensuring the core autonomous loop is robust, observable, and extensible.

-   **[In Progress] Core Logic Implementation**: Implement the full perception-decision-action-reflection loop in `main.py`.
-   **[Done] Bug-fixing and Stability**: Resolve critical bugs, such as the process hang and high memory usage.
-   **[Done] Documentation**: Update `README.md` and `context.md` to reflect the new architecture.
-   **[Next Up] Enhanced Logging & Observability**: Improve the logging to provide a clearer "train of thought" for the AGI. This includes creating a dedicated "decision log" that tracks why certain plans were chosen.
-   **[Next Up] Refine Situation Generation**: Add more variety and complexity to the situations generated by the `SituationGenerator`, including multi-step problems.

## Phase 2: Enhance Intelligence and Decision-Making

Once the core loop is stable, the focus will shift to making the AGI "smarter."

-   **Advanced Decision Engine**:
    -   Move beyond simple goal creation. Implement a more sophisticated planning system (e.g., using a library like `langchain-plan-and-execute` or a custom HTN-style planner).
    -   The Decision Engine should be able to choose from a variety of "tools" (i.e., other modules) to achieve its goals. For example, if the situation is a technical challenge, it should decide to use a code execution tool.
-   **Integrate Curiosity and Experimentation**:
    -   The `CuriosityTrigger` and `AGIExperimentation` modules are currently disconnected. They should be integrated into the main loop.
    -   The AGI should be able to decide *when* to be curious. For example, if its emotional state is "Bored" or "Stuck," it could trigger the curiosity module to find a new topic to explore.
    -   The AGI should be able to form hypotheses based on its reflections and then use the `AGIExperimentation` module to design and run experiments to test them.
-   **Dynamic Self-Improvement**:
    -   The `AgentSelfReflection` module should do more than just generate text. It should identify flaws in its own logic and propose concrete improvements.
    -   This could involve suggesting changes to its own prompts, modifying the weights in its decision-making process, or even flagging parts of its own code for review (a form of automated code improvement).

## Phase 3: Expand Capabilities and Knowledge

With a "smarter" AGI, the next step is to broaden its horizons.

-   **Multi-modal Input**: Integrate modules that can process more than just text. This includes:
    -   **Vision**: Allow the AGI to analyze images.
    -   **Audio**: Enable the AGI to process and understand spoken language or other sounds.
-   **Expanded Toolset**: Give the AGI more ways to interact with the world. This could include:
    -   **Web Browsing**: Allow the AGI to search the web to find up-to-date information.
    -   **Code Execution**: A secure environment where the AGI can write and run code to solve problems.
    -   **API Integration**: The ability to interact with third-party APIs.
-   **Long-Term Memory & Knowledge Graphs**:
    -   The current `EpisodicMemory` is good for storing experiences, but the AGI also needs a more structured knowledge base.
    -   Implement a knowledge graph to store facts and relationships between them. This will allow for more complex reasoning and a deeper understanding of the world.

## Phase 4: Towards More General Intelligence

This is the long-term vision for the project.

-   **Meta-Learning**: The AGI should be able to improve its own learning algorithms. It should reflect not just on its actions, but on *how* it learns, and try to optimize that process.
-   **Social Intelligence**: Develop modules that allow the AGI to understand and engage in complex social dynamics, including collaboration with other agents (human or AI).
-   **Embodied Cognition**: Connect the AGI to a simulated or physical robotic body, allowing it to learn from direct interaction with the environment.
